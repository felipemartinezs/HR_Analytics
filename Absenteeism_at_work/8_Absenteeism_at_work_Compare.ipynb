{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/hypnobear/absenteeism-at-work-dataset\n",
    "\n",
    "https://www.kaggle.com/chetnasureka/absenteeismatwork/kernels\n",
    "\n",
    "https://www.kaggle.com/shreytiwari/name-na\n",
    "\n",
    "https://www.kaggle.com/miner16078/zenith-classification-and-clustering\n",
    "\n",
    "https://www.kaggle.com/tejprash/theaggregatr-assign6\n",
    "\n",
    "https://www.kaggle.com/kerneler/starter-absenteeism-at-work-7c360987-f\n",
    "\n",
    "https://www.kaggle.com/dweepa/outliers-assign6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Machine Learning Algorithms\n",
    "\n",
    "It is important to compare the performance of multiple diferent machine learning algorithms\n",
    "consistently. In this chapter you will discover how you can create a test harness to compare\n",
    "multiple diferent machine learning algorithms in Python with scikit-learn. You can use this\n",
    "test harness as a template on your own machine learning problems and add more and diferent\n",
    "algorithms to compare. After completing this lesson you will know:\n",
    "1. How to formulate an experiment to directly compare machine learning algorithms.\n",
    "2. A reusable template for evaluating the performance of multiple algorithms on one dataset.\n",
    "3. How to report and visualize the results when comparing algorithm performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose The Best Machine Learning Model\n",
    "\n",
    "When you work on a machine learning project, you often end up with multiple good models\n",
    "to choose from. Each model will have diferent performance characteristics. Using resampling\n",
    "methods like cross-validation, you can get an estimate for how accurate each model may be on\n",
    "unseen data. You need to be able to use these estimates to choose one or two best models from\n",
    "the suite of models that you have created.\n",
    "When you have a new dataset, it is a good idea to visualize the data using diferent techniques\n",
    "in order to look at the data from diferent perspectives. The same idea applies to model selection.\n",
    "You should use a number of diferent ways of looking at the estimated accuracy of your machine\n",
    "learning algorithms in order to choose the one or two algorithms to finalize. A way to do this is\n",
    "to use visualization methods to show the average accuracy, variance and other properties of the\n",
    "distribution of model accuracies. In the next section you will discover exactly how you can do\n",
    "that in Python with scikit-learn.\n",
    "\n",
    "\n",
    "## Compare Machine Learning Algorithms Consistently\n",
    "The key to a fair comparison of machine learning algorithms is ensuring that each algorithm is\n",
    "evaluated in the same way on the same data. You can achieve this by forcing each algorithm to be evaluated on a consistent test harness. In the example below six diferent classification\n",
    "algorithms are compared on a single dataset:\n",
    "\n",
    "- Logistic Regression.\n",
    "- Linear Discriminant Analysis.\n",
    "- k-Nearest Neighbors.\n",
    "- Classification and Regression Trees.\n",
    "- Naive Bayes.\n",
    "- Support Vector Machines.\n",
    "\n",
    "The dataset is the Pima Indians onset of diabetes problem. The problem has two classes and\n",
    "eight numeric input variables of varying scales. The 10-fold cross-validation procedure is used to\n",
    "evaluate each algorithm, importantly con\f",
    "gured with the same random seed to ensure that the\n",
    "same splits to the training data are performed and that each algorithm is evaluated in precisely\n",
    "the same way. Each algorithm is given a short name, useful for summarizing results afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Absenteeism_at_work.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Reason for absence</th>\n",
       "      <th>Month of absence</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Transportation expense</th>\n",
       "      <th>Distance from Residence to Work</th>\n",
       "      <th>Service time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work load Average/day</th>\n",
       "      <th>Hit target</th>\n",
       "      <th>Disciplinary failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Absenteeism time in hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>361</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>246</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>248</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>47</td>\n",
       "      <td>205.917</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  Reason for absence  Month of absence  Day of the week  Seasons  \\\n",
       "0   11                  26                 7                3        1   \n",
       "1   36                   0                 7                3        1   \n",
       "2    3                  23                 7                4        1   \n",
       "3    7                   7                 7                5        1   \n",
       "4   11                  23                 7                5        1   \n",
       "5    3                  23                 7                6        1   \n",
       "6   10                  22                 7                6        1   \n",
       "7   20                  23                 7                6        1   \n",
       "8   14                  19                 7                2        1   \n",
       "9    1                  22                 7                2        1   \n",
       "10  20                   1                 7                2        1   \n",
       "11  20                   1                 7                3        1   \n",
       "12  20                  11                 7                4        1   \n",
       "13   3                  11                 7                4        1   \n",
       "14   3                  23                 7                4        1   \n",
       "15  24                  14                 7                6        1   \n",
       "16   3                  23                 7                6        1   \n",
       "17   3                  21                 7                2        1   \n",
       "18   6                  11                 7                5        1   \n",
       "19  33                  23                 8                4        1   \n",
       "\n",
       "    Transportation expense  Distance from Residence to Work  Service time  \\\n",
       "0                      289                               36            13   \n",
       "1                      118                               13            18   \n",
       "2                      179                               51            18   \n",
       "3                      279                                5            14   \n",
       "4                      289                               36            13   \n",
       "5                      179                               51            18   \n",
       "6                      361                               52             3   \n",
       "7                      260                               50            11   \n",
       "8                      155                               12            14   \n",
       "9                      235                               11            14   \n",
       "10                     260                               50            11   \n",
       "11                     260                               50            11   \n",
       "12                     260                               50            11   \n",
       "13                     179                               51            18   \n",
       "14                     179                               51            18   \n",
       "15                     246                               25            16   \n",
       "16                     179                               51            18   \n",
       "17                     179                               51            18   \n",
       "18                     189                               29            13   \n",
       "19                     248                               25            14   \n",
       "\n",
       "    Age  Work load Average/day   Hit target  Disciplinary failure  Education  \\\n",
       "0    33                 239.554          97                     0          1   \n",
       "1    50                 239.554          97                     1          1   \n",
       "2    38                 239.554          97                     0          1   \n",
       "3    39                 239.554          97                     0          1   \n",
       "4    33                 239.554          97                     0          1   \n",
       "5    38                 239.554          97                     0          1   \n",
       "6    28                 239.554          97                     0          1   \n",
       "7    36                 239.554          97                     0          1   \n",
       "8    34                 239.554          97                     0          1   \n",
       "9    37                 239.554          97                     0          3   \n",
       "10   36                 239.554          97                     0          1   \n",
       "11   36                 239.554          97                     0          1   \n",
       "12   36                 239.554          97                     0          1   \n",
       "13   38                 239.554          97                     0          1   \n",
       "14   38                 239.554          97                     0          1   \n",
       "15   41                 239.554          97                     0          1   \n",
       "16   38                 239.554          97                     0          1   \n",
       "17   38                 239.554          97                     0          1   \n",
       "18   33                 239.554          97                     0          1   \n",
       "19   47                 205.917          92                     0          1   \n",
       "\n",
       "    Body mass index  Absenteeism time in hours  \n",
       "0                30                          4  \n",
       "1                31                          0  \n",
       "2                31                          2  \n",
       "3                24                          4  \n",
       "4                30                          2  \n",
       "5                31                          2  \n",
       "6                27                          8  \n",
       "7                23                          4  \n",
       "8                25                         40  \n",
       "9                29                          8  \n",
       "10               23                          8  \n",
       "11               23                          8  \n",
       "12               23                          8  \n",
       "13               31                          1  \n",
       "14               31                          4  \n",
       "15               23                          8  \n",
       "16               31                          2  \n",
       "17               31                          8  \n",
       "18               25                          8  \n",
       "19               32                          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(740, 15)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = data.values\n",
    "X = array[:,0:15]\n",
    "Y = array[:,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.610811 (0.072973)\n",
      "LDA: 0.427027 (0.055455)\n",
      "KNN: 0.366216 (0.031663)\n",
      "CART: 0.986486 (0.010468)\n",
      "NB: 0.983784 (0.014554)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.306757 (0.044430)\n"
     ]
    }
   ],
   "source": [
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# boxplot algorithm comparison\n",
    "fig = pyplot.figure(figsize=(10,8))\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
