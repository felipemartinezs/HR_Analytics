{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/hypnobear/absenteeism-at-work-dataset\n",
    "\n",
    "https://www.kaggle.com/chetnasureka/absenteeismatwork/kernels\n",
    "\n",
    "https://www.kaggle.com/shreytiwari/name-na\n",
    "\n",
    "https://www.kaggle.com/miner16078/zenith-classification-and-clustering\n",
    "\n",
    "https://www.kaggle.com/tejprash/theaggregatr-assign6\n",
    "\n",
    "https://www.kaggle.com/kerneler/starter-absenteeism-at-work-7c360987-f\n",
    "\n",
    "https://www.kaggle.com/dweepa/outliers-assign6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Your Data For Machine Learning\n",
    "Many machine learning algorithms make assumptions about your data. It is often a very good\n",
    "idea to prepare your data in such a way to best expose the structure of the problem to the\n",
    "machine learning algorithms that you intend to use. In this chapter you will discover how to\n",
    "prepare your data for machine learning in Python using scikit-learn. After completing this\n",
    "lesson you will know how to:\n",
    "1. Rescale data.\n",
    "2. Standardize data.\n",
    "3. Normalize data.\n",
    "4. Binarize data. \n",
    "\n",
    "\n",
    "## Need For Data Pre-processing\n",
    "You almost always need to pre-process your data. It is a required step. A dificulty is that\n",
    "diferent algorithms make diferent assumptions about your data and may require diferent\n",
    "transforms. Further, when you follow all of the rules and prepare your data, sometimes algorithms\n",
    "can deliver better results without pre-processing.\n",
    "Generally, I would recommend creating many diferent views and transforms of your data,\n",
    "then exercise a handful of algorithms on each view of your dataset. This will help you to \n",
    "ush\n",
    "out which data transforms might be better at exposing the structure of your problem in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transforms\n",
    "\n",
    "\n",
    "In this lesson you will work through 4 di\u000b",
    "erent data pre-processing recipes for machine learning.\n",
    "The Pima Indian diabetes dataset is used in each recipe. Each recipe follows the same structure:\n",
    "- Load the dataset.\n",
    "\n",
    "- Split the dataset into the input and output variables for machine learning.\n",
    "- Apply a pre-processing transform to the input variables.\n",
    "- Summarize the data to show the change.\n",
    "\n",
    "\n",
    "The scikit-learn library provides two standard idioms for transforming data. Each are useful\n",
    "in diferent circumstances. The transforms are calculated in such a way that they can be applied\n",
    "to your training data and any samples of data you may have in the future. The scikit-learn\n",
    "documentation has some information on how to use various diferent pre-processing methods:\n",
    "\n",
    "- Fit and Multiple Transform.\n",
    "- Combined Fit-And-Transform.\n",
    "\n",
    "The Fit and Multiple Transform method is the preferred approach. You call the fit()\n",
    "function to prepare the parameters of the transform once on your data. Then later you can use\n",
    "the transform() function on the same data to prepare it for modeling and again on the test or\n",
    "validation dataset or new data that you may see in the future. The Combined Fit-And-Transform\n",
    "is a convenience that you can use for one o\u000b",
    " tasks. This might be useful if you are interested\n",
    "in plotting or summarizing the transformed data. You can review the preprocess API in\n",
    "scikit-learn here1.\n",
    "\n",
    "\n",
    "## Rescale Data\n",
    "When your data is comprised of attributes with varying scales, many machine learning algorithms\n",
    "can benefit from rescaling the attributes to all have the same scale. Often this is referred to\n",
    "as normalization and attributes are often rescaled into the range between 0 and 1. This is\n",
    "useful for optimization algorithms used in the core of machine learning algorithms like gradient\n",
    "descent. It is also useful for algorithms that weight inputs like regression and neural networks\n",
    "and algorithms that use distance measures like k-Nearest Neighbors. You can rescale your data\n",
    "using scikit-learn using the MinMaxScaler class2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale data (between 0 and 1)\n",
    "from numpy import set_printoptions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Absenteeism_at_work.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Reason for absence</th>\n",
       "      <th>Month of absence</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Transportation expense</th>\n",
       "      <th>Distance from Residence to Work</th>\n",
       "      <th>Service time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work load Average/day</th>\n",
       "      <th>Hit target</th>\n",
       "      <th>Disciplinary failure</th>\n",
       "      <th>Education</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Absenteeism time in hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>361</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>246</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>248</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>47</td>\n",
       "      <td>205.917</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  Reason for absence  Month of absence  Day of the week  Seasons  \\\n",
       "0   11                  26                 7                3        1   \n",
       "1   36                   0                 7                3        1   \n",
       "2    3                  23                 7                4        1   \n",
       "3    7                   7                 7                5        1   \n",
       "4   11                  23                 7                5        1   \n",
       "5    3                  23                 7                6        1   \n",
       "6   10                  22                 7                6        1   \n",
       "7   20                  23                 7                6        1   \n",
       "8   14                  19                 7                2        1   \n",
       "9    1                  22                 7                2        1   \n",
       "10  20                   1                 7                2        1   \n",
       "11  20                   1                 7                3        1   \n",
       "12  20                  11                 7                4        1   \n",
       "13   3                  11                 7                4        1   \n",
       "14   3                  23                 7                4        1   \n",
       "15  24                  14                 7                6        1   \n",
       "16   3                  23                 7                6        1   \n",
       "17   3                  21                 7                2        1   \n",
       "18   6                  11                 7                5        1   \n",
       "19  33                  23                 8                4        1   \n",
       "\n",
       "    Transportation expense  Distance from Residence to Work  Service time  \\\n",
       "0                      289                               36            13   \n",
       "1                      118                               13            18   \n",
       "2                      179                               51            18   \n",
       "3                      279                                5            14   \n",
       "4                      289                               36            13   \n",
       "5                      179                               51            18   \n",
       "6                      361                               52             3   \n",
       "7                      260                               50            11   \n",
       "8                      155                               12            14   \n",
       "9                      235                               11            14   \n",
       "10                     260                               50            11   \n",
       "11                     260                               50            11   \n",
       "12                     260                               50            11   \n",
       "13                     179                               51            18   \n",
       "14                     179                               51            18   \n",
       "15                     246                               25            16   \n",
       "16                     179                               51            18   \n",
       "17                     179                               51            18   \n",
       "18                     189                               29            13   \n",
       "19                     248                               25            14   \n",
       "\n",
       "    Age  Work load Average/day   Hit target  Disciplinary failure  Education  \\\n",
       "0    33                 239.554          97                     0          1   \n",
       "1    50                 239.554          97                     1          1   \n",
       "2    38                 239.554          97                     0          1   \n",
       "3    39                 239.554          97                     0          1   \n",
       "4    33                 239.554          97                     0          1   \n",
       "5    38                 239.554          97                     0          1   \n",
       "6    28                 239.554          97                     0          1   \n",
       "7    36                 239.554          97                     0          1   \n",
       "8    34                 239.554          97                     0          1   \n",
       "9    37                 239.554          97                     0          3   \n",
       "10   36                 239.554          97                     0          1   \n",
       "11   36                 239.554          97                     0          1   \n",
       "12   36                 239.554          97                     0          1   \n",
       "13   38                 239.554          97                     0          1   \n",
       "14   38                 239.554          97                     0          1   \n",
       "15   41                 239.554          97                     0          1   \n",
       "16   38                 239.554          97                     0          1   \n",
       "17   38                 239.554          97                     0          1   \n",
       "18   33                 239.554          97                     0          1   \n",
       "19   47                 205.917          92                     0          1   \n",
       "\n",
       "    Body mass index  Absenteeism time in hours  \n",
       "0                30                          4  \n",
       "1                31                          0  \n",
       "2                31                          2  \n",
       "3                24                          4  \n",
       "4                30                          2  \n",
       "5                31                          2  \n",
       "6                27                          8  \n",
       "7                23                          4  \n",
       "8                25                         40  \n",
       "9                29                          8  \n",
       "10               23                          8  \n",
       "11               23                          8  \n",
       "12               23                          8  \n",
       "13               31                          1  \n",
       "14               31                          4  \n",
       "15               23                          8  \n",
       "16               31                          2  \n",
       "17               31                          8  \n",
       "18               25                          8  \n",
       "19               32                          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(740, 15)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11., 26.,  7., ...,  1., 30.,  4.],\n",
       "       [36.,  0.,  7., ...,  1., 31.,  0.],\n",
       "       [ 3., 23.,  7., ...,  1., 31.,  2.],\n",
       "       ...,\n",
       "       [ 4.,  0.,  0., ...,  1., 34.,  0.],\n",
       "       [ 8.,  0.,  0., ...,  1., 35.,  0.],\n",
       "       [35.,  0.,  0., ...,  1., 25.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = data.values\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11., 26.,  7., ...,  1., 30.,  4.],\n",
       "       [36.,  0.,  7., ...,  1., 31.,  0.],\n",
       "       [ 3., 23.,  7., ...,  1., 31.,  2.],\n",
       "       ...,\n",
       "       [ 4.,  0.,  0., ...,  1., 34.,  0.],\n",
       "       [ 8.,  0.,  0., ...,  1., 35.,  0.],\n",
       "       [35.,  0.,  0., ...,  1., 25.,  0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate array into input and output components\n",
    "X = array[:,0:15]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 15)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = array[:,14]\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.286, 0.929, 0.583, ..., 0.   , 0.579, 0.033],\n",
       "       [1.   , 0.   , 0.583, ..., 0.   , 0.632, 0.   ],\n",
       "       [0.057, 0.821, 0.583, ..., 0.   , 0.632, 0.017],\n",
       "       ...,\n",
       "       [0.086, 0.   , 0.   , ..., 0.   , 0.789, 0.   ],\n",
       "       [0.2  , 0.   , 0.   , ..., 0.   , 0.842, 0.   ],\n",
       "       [0.971, 0.   , 0.   , ..., 0.   , 0.316, 0.   ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaledX = scaler.fit_transform(X)\n",
    "rescaledX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize transformed data\n",
    "set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.286 0.929 0.583 0.25  0.    0.633 0.66  0.429 0.194 0.194 0.842 0.\n",
      "  0.    0.579 0.033]\n",
      " [1.    0.    0.583 0.25  0.    0.    0.17  0.607 0.742 0.194 0.842 1.\n",
      "  0.    0.632 0.   ]\n",
      " [0.057 0.821 0.583 0.5   0.    0.226 0.979 0.607 0.355 0.194 0.842 0.\n",
      "  0.    0.632 0.017]\n",
      " [0.171 0.25  0.583 0.75  0.    0.596 0.    0.464 0.387 0.194 0.842 0.\n",
      "  0.    0.263 0.033]\n",
      " [0.286 0.821 0.583 0.75  0.    0.633 0.66  0.429 0.194 0.194 0.842 0.\n",
      "  0.    0.579 0.017]]\n"
     ]
    }
   ],
   "source": [
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 15)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaledX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Data\n",
    "\n",
    "Standardization is a useful technique to transform attributes with a Gaussian distribution and\n",
    "differing means and standard deviations to a standard Gaussian distribution with a mean of\n",
    "0 and a standard deviation of 1. It is most suitable for techniques that assume a Gaussian\n",
    "distribution in the input variables and work better with rescaled data, such as linear regression,\n",
    "logistic regression and linear discriminate analysis. You can standardize data using scikit-learn\n",
    "with the StandardScaler class3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data (0 mean, 1 stdev)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import set_printoptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11., 26.,  7., ...,  1., 30.,  4.],\n",
       "       [36.,  0.,  7., ...,  1., 31.,  0.],\n",
       "       [ 3., 23.,  7., ...,  1., 31.,  2.],\n",
       "       ...,\n",
       "       [ 4.,  0.,  0., ...,  1., 34.,  0.],\n",
       "       [ 8.,  0.,  0., ...,  1., 35.,  0.],\n",
       "       [35.,  0.,  0., ...,  1., 25.,  0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_std_data = data.values\n",
    "array_std_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 15)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_std_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11., 26.,  7., ...,  1., 30.,  4.],\n",
       "       [36.,  0.,  7., ...,  1., 31.,  0.],\n",
       "       [ 3., 23.,  7., ...,  1., 31.,  2.],\n",
       "       ...,\n",
       "       [ 4.,  0.,  0., ...,  1., 34.,  0.],\n",
       "       [ 8.,  0.,  0., ...,  1., 35.,  0.],\n",
       "       [35.,  0.,  0., ...,  1., 25.,  0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate array into input and output components\n",
    "X_ = array[:,0:15]\n",
    "X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 15)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.,   0.,   2.,   4.,   2.,   2.,   8.,   4.,  40.,   8.,   8.,\n",
       "         8.,   8.,   1.,   4.,   8.,   2.,   8.,   8.,   2.,   8.,   1.,\n",
       "        40.,   4.,   8.,   7.,   1.,   4.,   8.,   2.,   8.,   8.,   4.,\n",
       "         8.,   2.,   1.,   8.,   4.,   8.,   4.,   2.,   4.,   4.,   8.,\n",
       "         2.,   3.,   3.,   4.,   8.,  32.,   0.,   0.,   2.,   2.,   0.,\n",
       "         0.,   3.,   3.,   0.,   1.,   3.,   4.,   3.,   3.,   0.,   1.,\n",
       "         3.,   3.,   3.,   2.,   2.,   5.,   8.,   3.,  16.,   8.,   2.,\n",
       "         8.,   1.,   3.,   1.,   1.,   8.,   8.,   5.,  32.,   8.,  40.,\n",
       "         1.,   8.,   3.,   8.,   3.,   4.,   1.,   3.,  24.,   3.,   1.,\n",
       "        64.,   2.,   8.,   2.,   8.,  56.,   8.,   3.,   3.,   2.,   8.,\n",
       "         2.,   8.,   2.,   1.,   1.,   1.,   8.,   2.,   2.,   2.,   1.,\n",
       "         2.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,   8.,   8.,   2.,\n",
       "         2.,   2.,   0.,   1.,   3.,   1.,   8.,   8.,   2.,   8.,   2.,\n",
       "         8.,   8.,   8.,   2.,   2.,   1.,   8.,   3.,   8.,   1.,   1.,\n",
       "         8.,   2.,   8.,   3.,   8.,   8.,   8.,   8.,   3.,  40.,  40.,\n",
       "        16.,  16.,   8.,   8.,   8.,   4.,   1.,   8.,  24.,   2.,   8.,\n",
       "         1.,   8.,  16.,   3.,  16.,   2.,   3.,   1.,   1.,   1.,   1.,\n",
       "        24.,   1.,   2.,   4.,  24.,   1.,   3.,   8.,   1.,   8.,  56.,\n",
       "         8.,  24.,   8.,  16.,   3.,   0.,   8.,   2.,   1.,   8.,   8.,\n",
       "         4.,   2.,   1.,  24.,   0.,   0.,   0.,   0.,   1.,  24.,   8.,\n",
       "         8.,   8.,  24.,   4.,   8.,   8.,   4.,   8.,   8.,  16.,   1.,\n",
       "        80.,   8.,   2.,   2.,   2.,  16.,   8.,   8.,   4.,   8.,   8.,\n",
       "         2.,   8.,   8.,   3.,   8.,   8.,   8.,  32.,   8.,   0.,   8.,\n",
       "         3.,   1.,   8.,   1.,   2.,   4.,   4.,   1.,   8.,   1.,   3.,\n",
       "         2.,   1.,   1.,   8.,   8.,   8.,   8.,   3.,  24.,   0.,  16.,\n",
       "         3.,   0.,   0.,   8.,  32.,   1.,   4.,   4.,   8.,   1.,   0.,\n",
       "         3.,  40.,   8.,   8.,   4.,   8.,   8.,   0.,   0.,   8.,   3.,\n",
       "         8.,   1.,  64.,   0.,  16.,   3.,   0.,   2.,   2.,   1.,   4.,\n",
       "        16.,   1.,   8.,   0.,   0.,   0.,   5.,   5.,   1.,   8.,   2.,\n",
       "         8.,   3.,   1.,   8., 120.,   8.,   0.,   1.,   3.,   2.,   3.,\n",
       "         8.,   4.,   8.,   1.,   8.,   8.,   0.,   0.,   1.,   3.,   2.,\n",
       "         1.,   3.,   1.,   4.,   8.,   1.,   1.,   1.,   8.,   2.,   1.,\n",
       "         8.,   4.,   8.,   2.,   3.,   8.,   5.,  32.,   2.,   1.,   4.,\n",
       "         8.,   8.,   8.,   4.,   1.,   1.,   2.,   3.,   1.,   3.,   3.,\n",
       "         3.,   2.,   3.,   8.,   8.,   3.,   8.,   3.,   2.,   2.,  16.,\n",
       "         3.,   3.,  24.,   3.,   3.,   8.,  16.,   2.,   4.,   2.,   8.,\n",
       "         8.,   8.,  16.,   8.,   0.,   8.,   2.,   3.,   8.,   0.,   0.,\n",
       "         0.,   8.,   8.,   8.,   2.,   4.,   3.,   4.,   4.,   4.,   8.,\n",
       "         8.,   1., 120.,   8.,   4.,   4.,   2.,  16.,   2.,   8.,   3.,\n",
       "         4.,   1.,   3.,   2.,   3.,   8.,   3.,   8.,   2.,   1.,   8.,\n",
       "         3.,   3.,   3.,   2.,   4.,   4.,   0.,  40.,  24.,   3.,   4.,\n",
       "         8.,   2.,   2.,   2.,   8.,   2.,   2.,   1.,   8.,   2.,   4.,\n",
       "         8.,   8.,   8.,   8.,   4.,   8.,   8.,   1.,   2., 112.,   1.,\n",
       "         1.,   8.,   8.,   8.,   2.,   1.,   2.,   4.,   1.,   4.,   4.,\n",
       "         8.,   8.,   4.,   4.,   8.,  16.,   4.,   1.,   5.,   2.,   3.,\n",
       "         1.,   1.,   3.,   2.,   2.,   8.,   1.,   4.,   1.,   2.,   8.,\n",
       "         8.,   1.,   3.,   8.,   3.,   2.,   2.,   2.,   1.,   2.,   8.,\n",
       "         3.,   4.,   8.,   3.,   1.,   1.,   8.,   1.,   8.,   3.,   8.,\n",
       "         8.,   8.,   0.,   3.,   1.,   3.,  24.,   1.,   8.,   8.,   8.,\n",
       "         4.,   8.,   2.,   2.,   3.,   1.,   8.,   8.,   2.,   0.,   0.,\n",
       "         4.,   0.,   2.,   8.,   2.,  32.,   1.,   3.,   1.,   3.,   3.,\n",
       "         4.,   2.,   8.,   8.,  16.,   2.,   3.,   2.,  80.,  24.,  16.,\n",
       "         2.,   2.,   3.,   2.,   8.,   3.,   2.,   8.,   2.,   3.,   8.,\n",
       "         3.,   2.,   8.,   3.,   8.,   2.,   3.,   2.,   2.,   2.,   2.,\n",
       "         2.,   2.,   8.,   3.,   3.,   3.,   2.,   2.,   3.,   3.,   2.,\n",
       "         2.,   8.,   2.,   5.,   3.,   2.,   2.,   2.,   2.,   2.,   2.,\n",
       "         2.,   2.,   2.,   2.,   3.,   3., 112.,   2.,   2.,   3.,   2.,\n",
       "         3.,   3.,   8.,   8.,   2.,   3.,   2.,   4.,   2.,   3.,   8.,\n",
       "         2.,   8.,   2.,   2.,   3.,   3.,   2.,   3.,   3.,   8.,  24.,\n",
       "         3.,   3.,   2., 104.,   8.,   8.,   8.,   8.,   8.,   8.,   2.,\n",
       "        24.,   2.,   3.,   2.,   2.,   8.,   2.,   8.,   3.,   2.,   4.,\n",
       "         8.,   2.,   2.,   8.,   3.,   2.,   3.,   8.,   1.,   2.,   8.,\n",
       "        64.,   8.,   2.,   2.,   3.,   1.,   0.,   2.,   0.,   1.,  48.,\n",
       "         8.,   8.,   8.,   3.,   8.,   2.,   2.,   2.,   8.,   2.,   8.,\n",
       "         8.,   1.,   8.,   3.,   8.,   8.,   8.,  24.,   8.,   2.,   0.,\n",
       "         0.,   3.,   2.,   2.,   3.,   3.,   8.,   2.,   3.,   3.,   4.,\n",
       "         2.,   8.,   4., 120.,  16.,   2.,   8.,   8.,  80.,   8.,   4.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_ = array[:,14]\n",
    "Y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X_)\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.637,  0.805,  0.197, ..., -0.434,  0.776, -0.22 ],\n",
       "       [ 1.633, -2.28 ,  0.197, ..., -0.434,  1.009, -0.52 ],\n",
       "       [-1.364,  0.449,  0.197, ..., -0.434,  1.009, -0.37 ],\n",
       "       ...,\n",
       "       [-1.273, -2.28 , -1.842, ..., -0.434,  1.71 , -0.52 ],\n",
       "       [-0.91 , -2.28 , -1.842, ..., -0.434,  1.943, -0.52 ],\n",
       "       [ 1.542, -2.28 , -1.842, ..., -0.434, -0.392, -0.52 ]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaledX_ = scaler.transform(X_)\n",
    "rescaledX_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize transformed data\n",
    "set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.637  0.805  0.197 -0.644 -1.39   1.011  0.43   0.102 -0.533 -0.818\n",
      "   0.639 -0.239 -0.434  0.776 -0.22 ]\n",
      " [ 1.633 -2.28   0.197 -0.644 -1.39  -1.544 -1.122  1.243  2.093 -0.818\n",
      "   0.639  4.183 -0.434  1.009 -0.52 ]\n",
      " [-1.364  0.449  0.197  0.06  -1.39  -0.633  1.441  1.243  0.239 -0.818\n",
      "   0.639 -0.239 -0.434  1.009 -0.37 ]\n",
      " [-1.    -1.45   0.197  0.764 -1.39   0.862 -1.661  0.33   0.394 -0.818\n",
      "   0.639 -0.239 -0.434 -0.625 -0.22 ]\n",
      " [-0.637  0.449  0.197  0.764 -1.39   1.011  0.43   0.102 -0.533 -0.818\n",
      "   0.639 -0.239 -0.434  0.776 -0.37 ]]\n"
     ]
    }
   ],
   "source": [
    "print(rescaledX_[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data\n",
    "Normalizing in scikit-learn refers to rescaling each observation (row) to have a length of 1 (called\n",
    "a unit norm or a vector with the length of 1 in linear algebra). This pre-processing method\n",
    "can be useful for sparse datasets (lots of zeros) with attributes of varying scales when using\n",
    "algorithms that weight input values such as neural networks and algorithms that use distance\n",
    "measures such as k-Nearest Neighbors. You can normalize data in Python with scikit-learn\n",
    "using the Normalizer class4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data (length of 1)\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from numpy import set_printoptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11., 26.,  7., ...,  1., 30.,  4.],\n",
       "       [36.,  0.,  7., ...,  1., 31.,  0.],\n",
       "       [ 3., 23.,  7., ...,  1., 31.,  2.],\n",
       "       ...,\n",
       "       [ 4.,  0.,  0., ...,  1., 34.,  0.],\n",
       "       [ 8.,  0.,  0., ...,  1., 35.,  0.],\n",
       "       [35.,  0.,  0., ...,  1., 25.,  0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_nor_data = data.values\n",
    "array_nor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 15)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_nor_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11., 26.,  7., ...,  1., 30.,  4.],\n",
       "       [36.,  0.,  7., ...,  1., 31.,  0.],\n",
       "       [ 3., 23.,  7., ...,  1., 31.,  2.],\n",
       "       ...,\n",
       "       [ 4.,  0.,  0., ...,  1., 34.,  0.],\n",
       "       [ 8.,  0.,  0., ...,  1., 35.,  0.],\n",
       "       [35.,  0.,  0., ...,  1., 25.,  0.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separ.shapeate array into input and output components\n",
    "X_nor = array[:,0:15]\n",
    "X_nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 15)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_nor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.,   0.,   2.,   4.,   2.,   2.,   8.,   4.,  40.,   8.,   8.,\n",
       "         8.,   8.,   1.,   4.,   8.,   2.,   8.,   8.,   2.,   8.,   1.,\n",
       "        40.,   4.,   8.,   7.,   1.,   4.,   8.,   2.,   8.,   8.,   4.,\n",
       "         8.,   2.,   1.,   8.,   4.,   8.,   4.,   2.,   4.,   4.,   8.,\n",
       "         2.,   3.,   3.,   4.,   8.,  32.,   0.,   0.,   2.,   2.,   0.,\n",
       "         0.,   3.,   3.,   0.,   1.,   3.,   4.,   3.,   3.,   0.,   1.,\n",
       "         3.,   3.,   3.,   2.,   2.,   5.,   8.,   3.,  16.,   8.,   2.,\n",
       "         8.,   1.,   3.,   1.,   1.,   8.,   8.,   5.,  32.,   8.,  40.,\n",
       "         1.,   8.,   3.,   8.,   3.,   4.,   1.,   3.,  24.,   3.,   1.,\n",
       "        64.,   2.,   8.,   2.,   8.,  56.,   8.,   3.,   3.,   2.,   8.,\n",
       "         2.,   8.,   2.,   1.,   1.,   1.,   8.,   2.,   2.,   2.,   1.,\n",
       "         2.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,   8.,   8.,   2.,\n",
       "         2.,   2.,   0.,   1.,   3.,   1.,   8.,   8.,   2.,   8.,   2.,\n",
       "         8.,   8.,   8.,   2.,   2.,   1.,   8.,   3.,   8.,   1.,   1.,\n",
       "         8.,   2.,   8.,   3.,   8.,   8.,   8.,   8.,   3.,  40.,  40.,\n",
       "        16.,  16.,   8.,   8.,   8.,   4.,   1.,   8.,  24.,   2.,   8.,\n",
       "         1.,   8.,  16.,   3.,  16.,   2.,   3.,   1.,   1.,   1.,   1.,\n",
       "        24.,   1.,   2.,   4.,  24.,   1.,   3.,   8.,   1.,   8.,  56.,\n",
       "         8.,  24.,   8.,  16.,   3.,   0.,   8.,   2.,   1.,   8.,   8.,\n",
       "         4.,   2.,   1.,  24.,   0.,   0.,   0.,   0.,   1.,  24.,   8.,\n",
       "         8.,   8.,  24.,   4.,   8.,   8.,   4.,   8.,   8.,  16.,   1.,\n",
       "        80.,   8.,   2.,   2.,   2.,  16.,   8.,   8.,   4.,   8.,   8.,\n",
       "         2.,   8.,   8.,   3.,   8.,   8.,   8.,  32.,   8.,   0.,   8.,\n",
       "         3.,   1.,   8.,   1.,   2.,   4.,   4.,   1.,   8.,   1.,   3.,\n",
       "         2.,   1.,   1.,   8.,   8.,   8.,   8.,   3.,  24.,   0.,  16.,\n",
       "         3.,   0.,   0.,   8.,  32.,   1.,   4.,   4.,   8.,   1.,   0.,\n",
       "         3.,  40.,   8.,   8.,   4.,   8.,   8.,   0.,   0.,   8.,   3.,\n",
       "         8.,   1.,  64.,   0.,  16.,   3.,   0.,   2.,   2.,   1.,   4.,\n",
       "        16.,   1.,   8.,   0.,   0.,   0.,   5.,   5.,   1.,   8.,   2.,\n",
       "         8.,   3.,   1.,   8., 120.,   8.,   0.,   1.,   3.,   2.,   3.,\n",
       "         8.,   4.,   8.,   1.,   8.,   8.,   0.,   0.,   1.,   3.,   2.,\n",
       "         1.,   3.,   1.,   4.,   8.,   1.,   1.,   1.,   8.,   2.,   1.,\n",
       "         8.,   4.,   8.,   2.,   3.,   8.,   5.,  32.,   2.,   1.,   4.,\n",
       "         8.,   8.,   8.,   4.,   1.,   1.,   2.,   3.,   1.,   3.,   3.,\n",
       "         3.,   2.,   3.,   8.,   8.,   3.,   8.,   3.,   2.,   2.,  16.,\n",
       "         3.,   3.,  24.,   3.,   3.,   8.,  16.,   2.,   4.,   2.,   8.,\n",
       "         8.,   8.,  16.,   8.,   0.,   8.,   2.,   3.,   8.,   0.,   0.,\n",
       "         0.,   8.,   8.,   8.,   2.,   4.,   3.,   4.,   4.,   4.,   8.,\n",
       "         8.,   1., 120.,   8.,   4.,   4.,   2.,  16.,   2.,   8.,   3.,\n",
       "         4.,   1.,   3.,   2.,   3.,   8.,   3.,   8.,   2.,   1.,   8.,\n",
       "         3.,   3.,   3.,   2.,   4.,   4.,   0.,  40.,  24.,   3.,   4.,\n",
       "         8.,   2.,   2.,   2.,   8.,   2.,   2.,   1.,   8.,   2.,   4.,\n",
       "         8.,   8.,   8.,   8.,   4.,   8.,   8.,   1.,   2., 112.,   1.,\n",
       "         1.,   8.,   8.,   8.,   2.,   1.,   2.,   4.,   1.,   4.,   4.,\n",
       "         8.,   8.,   4.,   4.,   8.,  16.,   4.,   1.,   5.,   2.,   3.,\n",
       "         1.,   1.,   3.,   2.,   2.,   8.,   1.,   4.,   1.,   2.,   8.,\n",
       "         8.,   1.,   3.,   8.,   3.,   2.,   2.,   2.,   1.,   2.,   8.,\n",
       "         3.,   4.,   8.,   3.,   1.,   1.,   8.,   1.,   8.,   3.,   8.,\n",
       "         8.,   8.,   0.,   3.,   1.,   3.,  24.,   1.,   8.,   8.,   8.,\n",
       "         4.,   8.,   2.,   2.,   3.,   1.,   8.,   8.,   2.,   0.,   0.,\n",
       "         4.,   0.,   2.,   8.,   2.,  32.,   1.,   3.,   1.,   3.,   3.,\n",
       "         4.,   2.,   8.,   8.,  16.,   2.,   3.,   2.,  80.,  24.,  16.,\n",
       "         2.,   2.,   3.,   2.,   8.,   3.,   2.,   8.,   2.,   3.,   8.,\n",
       "         3.,   2.,   8.,   3.,   8.,   2.,   3.,   2.,   2.,   2.,   2.,\n",
       "         2.,   2.,   8.,   3.,   3.,   3.,   2.,   2.,   3.,   3.,   2.,\n",
       "         2.,   8.,   2.,   5.,   3.,   2.,   2.,   2.,   2.,   2.,   2.,\n",
       "         2.,   2.,   2.,   2.,   3.,   3., 112.,   2.,   2.,   3.,   2.,\n",
       "         3.,   3.,   8.,   8.,   2.,   3.,   2.,   4.,   2.,   3.,   8.,\n",
       "         2.,   8.,   2.,   2.,   3.,   3.,   2.,   3.,   3.,   8.,  24.,\n",
       "         3.,   3.,   2., 104.,   8.,   8.,   8.,   8.,   8.,   8.,   2.,\n",
       "        24.,   2.,   3.,   2.,   2.,   8.,   2.,   8.,   3.,   2.,   4.,\n",
       "         8.,   2.,   2.,   8.,   3.,   2.,   3.,   8.,   1.,   2.,   8.,\n",
       "        64.,   8.,   2.,   2.,   3.,   1.,   0.,   2.,   0.,   1.,  48.,\n",
       "         8.,   8.,   8.,   3.,   8.,   2.,   2.,   2.,   8.,   2.,   8.,\n",
       "         8.,   1.,   8.,   3.,   8.,   8.,   8.,  24.,   8.,   2.,   0.,\n",
       "         0.,   3.,   2.,   2.,   3.,   3.,   8.,   2.,   3.,   3.,   4.,\n",
       "         2.,   8.,   4., 120.,  16.,   2.,   8.,   8.,  80.,   8.,   4.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_nor = array[:,14]\n",
    "Y_nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_nor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normalizer(copy=True, norm='l2')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_nor_data = Normalizer().fit(X_nor)\n",
    "scaler_nor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.028, 0.066, 0.018, ..., 0.003, 0.076, 0.01 ],\n",
       "       [0.123, 0.   , 0.024, ..., 0.003, 0.106, 0.   ],\n",
       "       [0.009, 0.071, 0.022, ..., 0.003, 0.096, 0.006],\n",
       "       ...,\n",
       "       [0.013, 0.   , 0.   , ..., 0.003, 0.108, 0.   ],\n",
       "       [0.021, 0.   , 0.   , ..., 0.003, 0.093, 0.   ],\n",
       "       [0.1  , 0.   , 0.   , ..., 0.003, 0.072, 0.   ]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizedX = scaler.transform(X_nor)\n",
    "normalizedX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.028 0.066 0.018 0.008 0.003 0.735 0.092 0.033 0.084 0.609 0.247 0.\n",
      "  0.003 0.076 0.01 ]\n",
      " [0.123 0.    0.024 0.01  0.003 0.402 0.044 0.061 0.17  0.817 0.331 0.003\n",
      "  0.003 0.106 0.   ]\n",
      " [0.009 0.071 0.022 0.012 0.003 0.553 0.158 0.056 0.117 0.74  0.3   0.\n",
      "  0.003 0.096 0.006]\n",
      " [0.018 0.018 0.018 0.013 0.003 0.727 0.013 0.036 0.102 0.624 0.253 0.\n",
      "  0.003 0.063 0.01 ]\n",
      " [0.028 0.059 0.018 0.013 0.003 0.735 0.092 0.033 0.084 0.609 0.247 0.\n",
      "  0.003 0.076 0.005]]\n"
     ]
    }
   ],
   "source": [
    "# summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(normalizedX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarize Data (Make Binary)\n",
    "You can transform your data using a binary threshold. All values above the threshold are\n",
    "marked 1 and all equal to or below are marked as 0. This is called binarizing your data or\n",
    "thresholding your data. It can be useful when you have probabilities that you want to make\n",
    "into crisp values. It is also useful when feature engineering and you want to add new features\n",
    "that indicate something meaningful. You can create new binary attributes in Python using\n",
    "scikit-learn with the Binarizer class5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarization\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from numpy import set_printoptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11., 26.,  7., ...,  1., 30.,  4.],\n",
       "       [36.,  0.,  7., ...,  1., 31.,  0.],\n",
       "       [ 3., 23.,  7., ...,  1., 31.,  2.],\n",
       "       ...,\n",
       "       [ 4.,  0.,  0., ...,  1., 34.,  0.],\n",
       "       [ 8.,  0.,  0., ...,  1., 35.,  0.],\n",
       "       [35.,  0.,  0., ...,  1., 25.,  0.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_bin = data.values\n",
    "array_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 15)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_bin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11., 26.,  7., ...,  1., 30.,  4.],\n",
       "       [36.,  0.,  7., ...,  1., 31.,  0.],\n",
       "       [ 3., 23.,  7., ...,  1., 31.,  2.],\n",
       "       ...,\n",
       "       [ 4.,  0.,  0., ...,  1., 34.,  0.],\n",
       "       [ 8.,  0.,  0., ...,  1., 35.,  0.],\n",
       "       [35.,  0.,  0., ...,  1., 25.,  0.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate array into input and output components\n",
    "X_bin = array[:,0:15]\n",
    "X_bin         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.,   0.,   2.,   4.,   2.,   2.,   8.,   4.,  40.,   8.,   8.,\n",
       "         8.,   8.,   1.,   4.,   8.,   2.,   8.,   8.,   2.,   8.,   1.,\n",
       "        40.,   4.,   8.,   7.,   1.,   4.,   8.,   2.,   8.,   8.,   4.,\n",
       "         8.,   2.,   1.,   8.,   4.,   8.,   4.,   2.,   4.,   4.,   8.,\n",
       "         2.,   3.,   3.,   4.,   8.,  32.,   0.,   0.,   2.,   2.,   0.,\n",
       "         0.,   3.,   3.,   0.,   1.,   3.,   4.,   3.,   3.,   0.,   1.,\n",
       "         3.,   3.,   3.,   2.,   2.,   5.,   8.,   3.,  16.,   8.,   2.,\n",
       "         8.,   1.,   3.,   1.,   1.,   8.,   8.,   5.,  32.,   8.,  40.,\n",
       "         1.,   8.,   3.,   8.,   3.,   4.,   1.,   3.,  24.,   3.,   1.,\n",
       "        64.,   2.,   8.,   2.,   8.,  56.,   8.,   3.,   3.,   2.,   8.,\n",
       "         2.,   8.,   2.,   1.,   1.,   1.,   8.,   2.,   2.,   2.,   1.,\n",
       "         2.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,   8.,   8.,   2.,\n",
       "         2.,   2.,   0.,   1.,   3.,   1.,   8.,   8.,   2.,   8.,   2.,\n",
       "         8.,   8.,   8.,   2.,   2.,   1.,   8.,   3.,   8.,   1.,   1.,\n",
       "         8.,   2.,   8.,   3.,   8.,   8.,   8.,   8.,   3.,  40.,  40.,\n",
       "        16.,  16.,   8.,   8.,   8.,   4.,   1.,   8.,  24.,   2.,   8.,\n",
       "         1.,   8.,  16.,   3.,  16.,   2.,   3.,   1.,   1.,   1.,   1.,\n",
       "        24.,   1.,   2.,   4.,  24.,   1.,   3.,   8.,   1.,   8.,  56.,\n",
       "         8.,  24.,   8.,  16.,   3.,   0.,   8.,   2.,   1.,   8.,   8.,\n",
       "         4.,   2.,   1.,  24.,   0.,   0.,   0.,   0.,   1.,  24.,   8.,\n",
       "         8.,   8.,  24.,   4.,   8.,   8.,   4.,   8.,   8.,  16.,   1.,\n",
       "        80.,   8.,   2.,   2.,   2.,  16.,   8.,   8.,   4.,   8.,   8.,\n",
       "         2.,   8.,   8.,   3.,   8.,   8.,   8.,  32.,   8.,   0.,   8.,\n",
       "         3.,   1.,   8.,   1.,   2.,   4.,   4.,   1.,   8.,   1.,   3.,\n",
       "         2.,   1.,   1.,   8.,   8.,   8.,   8.,   3.,  24.,   0.,  16.,\n",
       "         3.,   0.,   0.,   8.,  32.,   1.,   4.,   4.,   8.,   1.,   0.,\n",
       "         3.,  40.,   8.,   8.,   4.,   8.,   8.,   0.,   0.,   8.,   3.,\n",
       "         8.,   1.,  64.,   0.,  16.,   3.,   0.,   2.,   2.,   1.,   4.,\n",
       "        16.,   1.,   8.,   0.,   0.,   0.,   5.,   5.,   1.,   8.,   2.,\n",
       "         8.,   3.,   1.,   8., 120.,   8.,   0.,   1.,   3.,   2.,   3.,\n",
       "         8.,   4.,   8.,   1.,   8.,   8.,   0.,   0.,   1.,   3.,   2.,\n",
       "         1.,   3.,   1.,   4.,   8.,   1.,   1.,   1.,   8.,   2.,   1.,\n",
       "         8.,   4.,   8.,   2.,   3.,   8.,   5.,  32.,   2.,   1.,   4.,\n",
       "         8.,   8.,   8.,   4.,   1.,   1.,   2.,   3.,   1.,   3.,   3.,\n",
       "         3.,   2.,   3.,   8.,   8.,   3.,   8.,   3.,   2.,   2.,  16.,\n",
       "         3.,   3.,  24.,   3.,   3.,   8.,  16.,   2.,   4.,   2.,   8.,\n",
       "         8.,   8.,  16.,   8.,   0.,   8.,   2.,   3.,   8.,   0.,   0.,\n",
       "         0.,   8.,   8.,   8.,   2.,   4.,   3.,   4.,   4.,   4.,   8.,\n",
       "         8.,   1., 120.,   8.,   4.,   4.,   2.,  16.,   2.,   8.,   3.,\n",
       "         4.,   1.,   3.,   2.,   3.,   8.,   3.,   8.,   2.,   1.,   8.,\n",
       "         3.,   3.,   3.,   2.,   4.,   4.,   0.,  40.,  24.,   3.,   4.,\n",
       "         8.,   2.,   2.,   2.,   8.,   2.,   2.,   1.,   8.,   2.,   4.,\n",
       "         8.,   8.,   8.,   8.,   4.,   8.,   8.,   1.,   2., 112.,   1.,\n",
       "         1.,   8.,   8.,   8.,   2.,   1.,   2.,   4.,   1.,   4.,   4.,\n",
       "         8.,   8.,   4.,   4.,   8.,  16.,   4.,   1.,   5.,   2.,   3.,\n",
       "         1.,   1.,   3.,   2.,   2.,   8.,   1.,   4.,   1.,   2.,   8.,\n",
       "         8.,   1.,   3.,   8.,   3.,   2.,   2.,   2.,   1.,   2.,   8.,\n",
       "         3.,   4.,   8.,   3.,   1.,   1.,   8.,   1.,   8.,   3.,   8.,\n",
       "         8.,   8.,   0.,   3.,   1.,   3.,  24.,   1.,   8.,   8.,   8.,\n",
       "         4.,   8.,   2.,   2.,   3.,   1.,   8.,   8.,   2.,   0.,   0.,\n",
       "         4.,   0.,   2.,   8.,   2.,  32.,   1.,   3.,   1.,   3.,   3.,\n",
       "         4.,   2.,   8.,   8.,  16.,   2.,   3.,   2.,  80.,  24.,  16.,\n",
       "         2.,   2.,   3.,   2.,   8.,   3.,   2.,   8.,   2.,   3.,   8.,\n",
       "         3.,   2.,   8.,   3.,   8.,   2.,   3.,   2.,   2.,   2.,   2.,\n",
       "         2.,   2.,   8.,   3.,   3.,   3.,   2.,   2.,   3.,   3.,   2.,\n",
       "         2.,   8.,   2.,   5.,   3.,   2.,   2.,   2.,   2.,   2.,   2.,\n",
       "         2.,   2.,   2.,   2.,   3.,   3., 112.,   2.,   2.,   3.,   2.,\n",
       "         3.,   3.,   8.,   8.,   2.,   3.,   2.,   4.,   2.,   3.,   8.,\n",
       "         2.,   8.,   2.,   2.,   3.,   3.,   2.,   3.,   3.,   8.,  24.,\n",
       "         3.,   3.,   2., 104.,   8.,   8.,   8.,   8.,   8.,   8.,   2.,\n",
       "        24.,   2.,   3.,   2.,   2.,   8.,   2.,   8.,   3.,   2.,   4.,\n",
       "         8.,   2.,   2.,   8.,   3.,   2.,   3.,   8.,   1.,   2.,   8.,\n",
       "        64.,   8.,   2.,   2.,   3.,   1.,   0.,   2.,   0.,   1.,  48.,\n",
       "         8.,   8.,   8.,   3.,   8.,   2.,   2.,   2.,   8.,   2.,   8.,\n",
       "         8.,   1.,   8.,   3.,   8.,   8.,   8.,  24.,   8.,   2.,   0.,\n",
       "         0.,   3.,   2.,   2.,   3.,   3.,   8.,   2.,   3.,   3.,   4.,\n",
       "         2.,   8.,   4., 120.,  16.,   2.,   8.,   8.,  80.,   8.,   4.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_bin = array[:,14]\n",
    "Y_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740,)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_bin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Binarizer(copy=True, threshold=0.0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer = Binarizer(threshold=0.0).fit(X_bin)\n",
    "binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 0., 1., ..., 1., 1., 0.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 1., 1., 0.],\n",
       "       [1., 0., 0., ..., 1., 1., 0.],\n",
       "       [1., 0., 0., ..., 1., 1., 0.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binaryX = binarizer.transform(X_bin)\n",
    "binaryX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 15)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binaryX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(binaryX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection For Machine Learning\n",
    "The data features that you use to train your machine learning models have a huge influence on\n",
    "the performance you can achieve. Irrelevant or partially relevant features can negatively impact\n",
    "model performance. In this chapter you will discover automatic feature selection techniques\n",
    "that you can use to prepare your machine learning data in Python with scikit-learn. After\n",
    "completing this lesson you will know how to use:\n",
    "\n",
    "1. Univariate Selection.\n",
    "2. Recursive Feature Elimination.\n",
    "3. Principle Component Analysis.\n",
    "4. Feature Importance.\n",
    "\n",
    "\n",
    "## Feature Selection\n",
    "\n",
    "Feature selection is a process where you automatically select those features in your data that\n",
    "contribute most to the prediction variable or output in which you are interested. Having\n",
    "irrelevant features in your data can decrease the accuracy of many models, especially linear\n",
    "algorithms like linear and logistic regression. Three bene\f",
    "ts of performing feature selection\n",
    "before modeling your data are:\n",
    "\n",
    "- Reduces Overfitting: Less redundant data means less opportunity to make decisions based on noise.\n",
    "- Improves Accuracy: Less misleading data means modeling accuracy improves.\n",
    "- Reduces Training Time: Less data means that algorithms train faster.\n",
    "\n",
    "You can learn more about feature selection with scikit-learn in the article Feature selection1.\n",
    "Each feature selection recipes will use the Pima Indians onset of diabetes dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Selection\n",
    "\n",
    "Statistical tests can be used to select those features that have the strongest relationship with\n",
    "the output variable. The scikit-learn library provides the SelectKBest class2 that can be used\n",
    "with a suite of diferent statistical tests to select a specific number of features. The example\n",
    "below uses the Chi-Squared (f2) statistical test for non-negative features to select 4 of the best\n",
    "features from the Pima Indians onset of diabetes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction with Univariate Statistical Tests (Chi-squared for classification)\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11., 26.,  7., ...,  1., 30.,  4.],\n",
       "       [36.,  0.,  7., ...,  1., 31.,  0.],\n",
       "       [ 3., 23.,  7., ...,  1., 31.,  2.],\n",
       "       ...,\n",
       "       [ 4.,  0.,  0., ...,  1., 34.,  0.],\n",
       "       [ 8.,  0.,  0., ...,  1., 35.,  0.],\n",
       "       [35.,  0.,  0., ...,  1., 25.,  0.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "array_univ_selec = data.values\n",
    "array_univ_selec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 15)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_univ_selec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11., 26.,  7., ...,  1., 30.,  4.],\n",
       "       [36.,  0.,  7., ...,  1., 31.,  0.],\n",
       "       [ 3., 23.,  7., ...,  1., 31.,  2.],\n",
       "       ...,\n",
       "       [ 4.,  0.,  0., ...,  1., 34.,  0.],\n",
       "       [ 8.,  0.,  0., ...,  1., 35.,  0.],\n",
       "       [35.,  0.,  0., ...,  1., 25.,  0.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_univ = array_univ_selec[:,0:15]\n",
    "X_univ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.,   0.,   2.,   4.,   2.,   2.,   8.,   4.,  40.,   8.,   8.,\n",
       "         8.,   8.,   1.,   4.,   8.,   2.,   8.,   8.,   2.,   8.,   1.,\n",
       "        40.,   4.,   8.,   7.,   1.,   4.,   8.,   2.,   8.,   8.,   4.,\n",
       "         8.,   2.,   1.,   8.,   4.,   8.,   4.,   2.,   4.,   4.,   8.,\n",
       "         2.,   3.,   3.,   4.,   8.,  32.,   0.,   0.,   2.,   2.,   0.,\n",
       "         0.,   3.,   3.,   0.,   1.,   3.,   4.,   3.,   3.,   0.,   1.,\n",
       "         3.,   3.,   3.,   2.,   2.,   5.,   8.,   3.,  16.,   8.,   2.,\n",
       "         8.,   1.,   3.,   1.,   1.,   8.,   8.,   5.,  32.,   8.,  40.,\n",
       "         1.,   8.,   3.,   8.,   3.,   4.,   1.,   3.,  24.,   3.,   1.,\n",
       "        64.,   2.,   8.,   2.,   8.,  56.,   8.,   3.,   3.,   2.,   8.,\n",
       "         2.,   8.,   2.,   1.,   1.,   1.,   8.,   2.,   2.,   2.,   1.,\n",
       "         2.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,   8.,   8.,   2.,\n",
       "         2.,   2.,   0.,   1.,   3.,   1.,   8.,   8.,   2.,   8.,   2.,\n",
       "         8.,   8.,   8.,   2.,   2.,   1.,   8.,   3.,   8.,   1.,   1.,\n",
       "         8.,   2.,   8.,   3.,   8.,   8.,   8.,   8.,   3.,  40.,  40.,\n",
       "        16.,  16.,   8.,   8.,   8.,   4.,   1.,   8.,  24.,   2.,   8.,\n",
       "         1.,   8.,  16.,   3.,  16.,   2.,   3.,   1.,   1.,   1.,   1.,\n",
       "        24.,   1.,   2.,   4.,  24.,   1.,   3.,   8.,   1.,   8.,  56.,\n",
       "         8.,  24.,   8.,  16.,   3.,   0.,   8.,   2.,   1.,   8.,   8.,\n",
       "         4.,   2.,   1.,  24.,   0.,   0.,   0.,   0.,   1.,  24.,   8.,\n",
       "         8.,   8.,  24.,   4.,   8.,   8.,   4.,   8.,   8.,  16.,   1.,\n",
       "        80.,   8.,   2.,   2.,   2.,  16.,   8.,   8.,   4.,   8.,   8.,\n",
       "         2.,   8.,   8.,   3.,   8.,   8.,   8.,  32.,   8.,   0.,   8.,\n",
       "         3.,   1.,   8.,   1.,   2.,   4.,   4.,   1.,   8.,   1.,   3.,\n",
       "         2.,   1.,   1.,   8.,   8.,   8.,   8.,   3.,  24.,   0.,  16.,\n",
       "         3.,   0.,   0.,   8.,  32.,   1.,   4.,   4.,   8.,   1.,   0.,\n",
       "         3.,  40.,   8.,   8.,   4.,   8.,   8.,   0.,   0.,   8.,   3.,\n",
       "         8.,   1.,  64.,   0.,  16.,   3.,   0.,   2.,   2.,   1.,   4.,\n",
       "        16.,   1.,   8.,   0.,   0.,   0.,   5.,   5.,   1.,   8.,   2.,\n",
       "         8.,   3.,   1.,   8., 120.,   8.,   0.,   1.,   3.,   2.,   3.,\n",
       "         8.,   4.,   8.,   1.,   8.,   8.,   0.,   0.,   1.,   3.,   2.,\n",
       "         1.,   3.,   1.,   4.,   8.,   1.,   1.,   1.,   8.,   2.,   1.,\n",
       "         8.,   4.,   8.,   2.,   3.,   8.,   5.,  32.,   2.,   1.,   4.,\n",
       "         8.,   8.,   8.,   4.,   1.,   1.,   2.,   3.,   1.,   3.,   3.,\n",
       "         3.,   2.,   3.,   8.,   8.,   3.,   8.,   3.,   2.,   2.,  16.,\n",
       "         3.,   3.,  24.,   3.,   3.,   8.,  16.,   2.,   4.,   2.,   8.,\n",
       "         8.,   8.,  16.,   8.,   0.,   8.,   2.,   3.,   8.,   0.,   0.,\n",
       "         0.,   8.,   8.,   8.,   2.,   4.,   3.,   4.,   4.,   4.,   8.,\n",
       "         8.,   1., 120.,   8.,   4.,   4.,   2.,  16.,   2.,   8.,   3.,\n",
       "         4.,   1.,   3.,   2.,   3.,   8.,   3.,   8.,   2.,   1.,   8.,\n",
       "         3.,   3.,   3.,   2.,   4.,   4.,   0.,  40.,  24.,   3.,   4.,\n",
       "         8.,   2.,   2.,   2.,   8.,   2.,   2.,   1.,   8.,   2.,   4.,\n",
       "         8.,   8.,   8.,   8.,   4.,   8.,   8.,   1.,   2., 112.,   1.,\n",
       "         1.,   8.,   8.,   8.,   2.,   1.,   2.,   4.,   1.,   4.,   4.,\n",
       "         8.,   8.,   4.,   4.,   8.,  16.,   4.,   1.,   5.,   2.,   3.,\n",
       "         1.,   1.,   3.,   2.,   2.,   8.,   1.,   4.,   1.,   2.,   8.,\n",
       "         8.,   1.,   3.,   8.,   3.,   2.,   2.,   2.,   1.,   2.,   8.,\n",
       "         3.,   4.,   8.,   3.,   1.,   1.,   8.,   1.,   8.,   3.,   8.,\n",
       "         8.,   8.,   0.,   3.,   1.,   3.,  24.,   1.,   8.,   8.,   8.,\n",
       "         4.,   8.,   2.,   2.,   3.,   1.,   8.,   8.,   2.,   0.,   0.,\n",
       "         4.,   0.,   2.,   8.,   2.,  32.,   1.,   3.,   1.,   3.,   3.,\n",
       "         4.,   2.,   8.,   8.,  16.,   2.,   3.,   2.,  80.,  24.,  16.,\n",
       "         2.,   2.,   3.,   2.,   8.,   3.,   2.,   8.,   2.,   3.,   8.,\n",
       "         3.,   2.,   8.,   3.,   8.,   2.,   3.,   2.,   2.,   2.,   2.,\n",
       "         2.,   2.,   8.,   3.,   3.,   3.,   2.,   2.,   3.,   3.,   2.,\n",
       "         2.,   8.,   2.,   5.,   3.,   2.,   2.,   2.,   2.,   2.,   2.,\n",
       "         2.,   2.,   2.,   2.,   3.,   3., 112.,   2.,   2.,   3.,   2.,\n",
       "         3.,   3.,   8.,   8.,   2.,   3.,   2.,   4.,   2.,   3.,   8.,\n",
       "         2.,   8.,   2.,   2.,   3.,   3.,   2.,   3.,   3.,   8.,  24.,\n",
       "         3.,   3.,   2., 104.,   8.,   8.,   8.,   8.,   8.,   8.,   2.,\n",
       "        24.,   2.,   3.,   2.,   2.,   8.,   2.,   8.,   3.,   2.,   4.,\n",
       "         8.,   2.,   2.,   8.,   3.,   2.,   3.,   8.,   1.,   2.,   8.,\n",
       "        64.,   8.,   2.,   2.,   3.,   1.,   0.,   2.,   0.,   1.,  48.,\n",
       "         8.,   8.,   8.,   3.,   8.,   2.,   2.,   2.,   8.,   2.,   8.,\n",
       "         8.,   1.,   8.,   3.,   8.,   8.,   8.,  24.,   8.,   2.,   0.,\n",
       "         0.,   3.,   2.,   2.,   3.,   3.,   8.,   2.,   3.,   3.,   4.,\n",
       "         2.,   8.,   4., 120.,  16.,   2.,   8.,   8.,  80.,   8.,   4.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_univ = array_univ_selec[:,14]\n",
    "Y_univ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_univ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=15, score_func=<function chi2 at 0x7fae9f39c488>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature extraction\n",
    "test = SelectKBest(score_func=chi2, k=15)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=15, score_func=<function chi2 at 0x7fae9f39c488>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit = test.fit(X_univ, Y_univ)\n",
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.933e+02 1.316e+03 7.598e+01 1.710e+01 2.178e+01 1.684e+03 2.242e+02\n",
      " 3.408e+01 3.606e+01 2.522e+02 5.757e+00 6.327e+02 6.053e+00 1.711e+01\n",
      " 1.897e+04]\n"
     ]
    }
   ],
   "source": [
    "# summarize scores\n",
    "set_printoptions(precision=3)\n",
    "print(fit.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11.     26.      7.      3.      1.    289.     36.     13.     33.\n",
      "  239.554  97.      0.      1.     30.      4.   ]\n",
      " [ 36.      0.      7.      3.      1.    118.     13.     18.     50.\n",
      "  239.554  97.      1.      1.     31.      0.   ]\n",
      " [  3.     23.      7.      4.      1.    179.     51.     18.     38.\n",
      "  239.554  97.      0.      1.     31.      2.   ]\n",
      " [  7.      7.      7.      5.      1.    279.      5.     14.     39.\n",
      "  239.554  97.      0.      1.     24.      4.   ]\n",
      " [ 11.     23.      7.      5.      1.    289.     36.     13.     33.\n",
      "  239.554  97.      0.      1.     30.      2.   ]]\n"
     ]
    }
   ],
   "source": [
    "features = fit.transform(X_univ)\n",
    "# summarize selected features\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 15)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination\n",
    "The Recursive Feature Elimination (or RFE) works by recursively removing attributes and\n",
    "building a model on those attributes that remain. It uses the model accuracy to identify which"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "Principal Component Analysis (or PCA) uses linear algebra to transform the dataset into a\n",
    "compressed form. Generally this is called a data reduction technique. A property of PCA is that\n",
    "you can choose the number of dimensions or principal components in the transformed result. In\n",
    "the example below, we use PCA and select 3 principal components. Learn more about the PCA\n",
    "class in scikit-learn by reviewing the API4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_pca = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11., 26.,  7., ...,  1., 30.,  4.],\n",
       "       [36.,  0.,  7., ...,  1., 31.,  0.],\n",
       "       [ 3., 23.,  7., ...,  1., 31.,  2.],\n",
       "       ...,\n",
       "       [ 4.,  0.,  0., ...,  1., 34.,  0.],\n",
       "       [ 8.,  0.,  0., ...,  1., 35.,  0.],\n",
       "       [35.,  0.,  0., ...,  1., 25.,  0.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca = array_pca[:,0:15]\n",
    "X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 15)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.,   0.,   2.,   4.,   2.,   2.,   8.,   4.,  40.,   8.,   8.,\n",
       "         8.,   8.,   1.,   4.,   8.,   2.,   8.,   8.,   2.,   8.,   1.,\n",
       "        40.,   4.,   8.,   7.,   1.,   4.,   8.,   2.,   8.,   8.,   4.,\n",
       "         8.,   2.,   1.,   8.,   4.,   8.,   4.,   2.,   4.,   4.,   8.,\n",
       "         2.,   3.,   3.,   4.,   8.,  32.,   0.,   0.,   2.,   2.,   0.,\n",
       "         0.,   3.,   3.,   0.,   1.,   3.,   4.,   3.,   3.,   0.,   1.,\n",
       "         3.,   3.,   3.,   2.,   2.,   5.,   8.,   3.,  16.,   8.,   2.,\n",
       "         8.,   1.,   3.,   1.,   1.,   8.,   8.,   5.,  32.,   8.,  40.,\n",
       "         1.,   8.,   3.,   8.,   3.,   4.,   1.,   3.,  24.,   3.,   1.,\n",
       "        64.,   2.,   8.,   2.,   8.,  56.,   8.,   3.,   3.,   2.,   8.,\n",
       "         2.,   8.,   2.,   1.,   1.,   1.,   8.,   2.,   2.,   2.,   1.,\n",
       "         2.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,   8.,   8.,   2.,\n",
       "         2.,   2.,   0.,   1.,   3.,   1.,   8.,   8.,   2.,   8.,   2.,\n",
       "         8.,   8.,   8.,   2.,   2.,   1.,   8.,   3.,   8.,   1.,   1.,\n",
       "         8.,   2.,   8.,   3.,   8.,   8.,   8.,   8.,   3.,  40.,  40.,\n",
       "        16.,  16.,   8.,   8.,   8.,   4.,   1.,   8.,  24.,   2.,   8.,\n",
       "         1.,   8.,  16.,   3.,  16.,   2.,   3.,   1.,   1.,   1.,   1.,\n",
       "        24.,   1.,   2.,   4.,  24.,   1.,   3.,   8.,   1.,   8.,  56.,\n",
       "         8.,  24.,   8.,  16.,   3.,   0.,   8.,   2.,   1.,   8.,   8.,\n",
       "         4.,   2.,   1.,  24.,   0.,   0.,   0.,   0.,   1.,  24.,   8.,\n",
       "         8.,   8.,  24.,   4.,   8.,   8.,   4.,   8.,   8.,  16.,   1.,\n",
       "        80.,   8.,   2.,   2.,   2.,  16.,   8.,   8.,   4.,   8.,   8.,\n",
       "         2.,   8.,   8.,   3.,   8.,   8.,   8.,  32.,   8.,   0.,   8.,\n",
       "         3.,   1.,   8.,   1.,   2.,   4.,   4.,   1.,   8.,   1.,   3.,\n",
       "         2.,   1.,   1.,   8.,   8.,   8.,   8.,   3.,  24.,   0.,  16.,\n",
       "         3.,   0.,   0.,   8.,  32.,   1.,   4.,   4.,   8.,   1.,   0.,\n",
       "         3.,  40.,   8.,   8.,   4.,   8.,   8.,   0.,   0.,   8.,   3.,\n",
       "         8.,   1.,  64.,   0.,  16.,   3.,   0.,   2.,   2.,   1.,   4.,\n",
       "        16.,   1.,   8.,   0.,   0.,   0.,   5.,   5.,   1.,   8.,   2.,\n",
       "         8.,   3.,   1.,   8., 120.,   8.,   0.,   1.,   3.,   2.,   3.,\n",
       "         8.,   4.,   8.,   1.,   8.,   8.,   0.,   0.,   1.,   3.,   2.,\n",
       "         1.,   3.,   1.,   4.,   8.,   1.,   1.,   1.,   8.,   2.,   1.,\n",
       "         8.,   4.,   8.,   2.,   3.,   8.,   5.,  32.,   2.,   1.,   4.,\n",
       "         8.,   8.,   8.,   4.,   1.,   1.,   2.,   3.,   1.,   3.,   3.,\n",
       "         3.,   2.,   3.,   8.,   8.,   3.,   8.,   3.,   2.,   2.,  16.,\n",
       "         3.,   3.,  24.,   3.,   3.,   8.,  16.,   2.,   4.,   2.,   8.,\n",
       "         8.,   8.,  16.,   8.,   0.,   8.,   2.,   3.,   8.,   0.,   0.,\n",
       "         0.,   8.,   8.,   8.,   2.,   4.,   3.,   4.,   4.,   4.,   8.,\n",
       "         8.,   1., 120.,   8.,   4.,   4.,   2.,  16.,   2.,   8.,   3.,\n",
       "         4.,   1.,   3.,   2.,   3.,   8.,   3.,   8.,   2.,   1.,   8.,\n",
       "         3.,   3.,   3.,   2.,   4.,   4.,   0.,  40.,  24.,   3.,   4.,\n",
       "         8.,   2.,   2.,   2.,   8.,   2.,   2.,   1.,   8.,   2.,   4.,\n",
       "         8.,   8.,   8.,   8.,   4.,   8.,   8.,   1.,   2., 112.,   1.,\n",
       "         1.,   8.,   8.,   8.,   2.,   1.,   2.,   4.,   1.,   4.,   4.,\n",
       "         8.,   8.,   4.,   4.,   8.,  16.,   4.,   1.,   5.,   2.,   3.,\n",
       "         1.,   1.,   3.,   2.,   2.,   8.,   1.,   4.,   1.,   2.,   8.,\n",
       "         8.,   1.,   3.,   8.,   3.,   2.,   2.,   2.,   1.,   2.,   8.,\n",
       "         3.,   4.,   8.,   3.,   1.,   1.,   8.,   1.,   8.,   3.,   8.,\n",
       "         8.,   8.,   0.,   3.,   1.,   3.,  24.,   1.,   8.,   8.,   8.,\n",
       "         4.,   8.,   2.,   2.,   3.,   1.,   8.,   8.,   2.,   0.,   0.,\n",
       "         4.,   0.,   2.,   8.,   2.,  32.,   1.,   3.,   1.,   3.,   3.,\n",
       "         4.,   2.,   8.,   8.,  16.,   2.,   3.,   2.,  80.,  24.,  16.,\n",
       "         2.,   2.,   3.,   2.,   8.,   3.,   2.,   8.,   2.,   3.,   8.,\n",
       "         3.,   2.,   8.,   3.,   8.,   2.,   3.,   2.,   2.,   2.,   2.,\n",
       "         2.,   2.,   8.,   3.,   3.,   3.,   2.,   2.,   3.,   3.,   2.,\n",
       "         2.,   8.,   2.,   5.,   3.,   2.,   2.,   2.,   2.,   2.,   2.,\n",
       "         2.,   2.,   2.,   2.,   3.,   3., 112.,   2.,   2.,   3.,   2.,\n",
       "         3.,   3.,   8.,   8.,   2.,   3.,   2.,   4.,   2.,   3.,   8.,\n",
       "         2.,   8.,   2.,   2.,   3.,   3.,   2.,   3.,   3.,   8.,  24.,\n",
       "         3.,   3.,   2., 104.,   8.,   8.,   8.,   8.,   8.,   8.,   2.,\n",
       "        24.,   2.,   3.,   2.,   2.,   8.,   2.,   8.,   3.,   2.,   4.,\n",
       "         8.,   2.,   2.,   8.,   3.,   2.,   3.,   8.,   1.,   2.,   8.,\n",
       "        64.,   8.,   2.,   2.,   3.,   1.,   0.,   2.,   0.,   1.,  48.,\n",
       "         8.,   8.,   8.,   3.,   8.,   2.,   2.,   2.,   8.,   2.,   8.,\n",
       "         8.,   1.,   8.,   3.,   8.,   8.,   8.,  24.,   8.,   2.,   0.,\n",
       "         0.,   3.,   2.,   2.,   3.,   3.,   8.,   2.,   3.,   3.,   4.,\n",
       "         2.,   8.,   4., 120.,  16.,   2.,   8.,   8.,  80.,   8.,   4.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pca = array[:,14]\n",
    "Y_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740,)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=3, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature extraction\n",
    "pca = PCA(n_components=3)\n",
    "pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=3, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit = pca.fit(X_pca)\n",
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance: [0.673 0.228 0.037]\n",
      "[[-3.853e-02 -1.486e-02  7.006e-03  7.375e-04  5.966e-04  9.967e-01\n",
      "   6.109e-02 -2.268e-02 -2.234e-02  3.733e-03 -4.534e-03  3.654e-04\n",
      "  -5.730e-04 -8.596e-03  5.488e-03]\n",
      " [ 3.041e-02 -2.848e-02 -1.494e-02  4.840e-04  4.317e-03 -1.204e-03\n",
      "  -3.298e-02 -6.058e-04 -6.215e-03  9.983e-01 -8.619e-03  1.861e-04\n",
      "  -1.220e-03 -1.055e-02  1.024e-02]\n",
      " [ 4.399e-01 -1.510e-01  1.647e-02 -9.818e-03  5.779e-03  6.322e-02\n",
      "  -8.398e-01 -8.429e-02  3.281e-02 -4.817e-02  9.506e-04  1.293e-03\n",
      "   8.099e-03 -6.649e-02  2.429e-01]]\n"
     ]
    }
   ],
   "source": [
    "# summarize components\n",
    "print(\"Explained Variance: %s\" % fit.explained_variance_ratio_)\n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "Bagged decision trees like Random Forest and Extra Trees can be used to estimate the importance\n",
    "of features. In the example below we construct a ExtraTreesClassifier classi\f",
    "er for the Pima\n",
    "Indians onset of diabetes dataset. You can learn more about the ExtraTreesClassifier class5\n",
    "in the scikit-learn API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance with Extra Trees Classifier\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11., 26.,  7., ...,  1., 30.,  4.],\n",
       "       [36.,  0.,  7., ...,  1., 31.,  0.],\n",
       "       [ 3., 23.,  7., ...,  1., 31.,  2.],\n",
       "       ...,\n",
       "       [ 4.,  0.,  0., ...,  1., 34.,  0.],\n",
       "       [ 8.,  0.,  0., ...,  1., 35.,  0.],\n",
       "       [35.,  0.,  0., ...,  1., 25.,  0.]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_feture_impor = data.values\n",
    "array_feture_impor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 15)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_feture_impor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11., 26.,  7., ...,  1., 30.,  4.],\n",
       "       [36.,  0.,  7., ...,  1., 31.,  0.],\n",
       "       [ 3., 23.,  7., ...,  1., 31.,  2.],\n",
       "       ...,\n",
       "       [ 4.,  0.,  0., ...,  1., 34.,  0.],\n",
       "       [ 8.,  0.,  0., ...,  1., 35.,  0.],\n",
       "       [35.,  0.,  0., ...,  1., 25.,  0.]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feature = array_feture_impor[:,0:15]\n",
    "X_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740, 15)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.,   0.,   2.,   4.,   2.,   2.,   8.,   4.,  40.,   8.,   8.,\n",
       "         8.,   8.,   1.,   4.,   8.,   2.,   8.,   8.,   2.,   8.,   1.,\n",
       "        40.,   4.,   8.,   7.,   1.,   4.,   8.,   2.,   8.,   8.,   4.,\n",
       "         8.,   2.,   1.,   8.,   4.,   8.,   4.,   2.,   4.,   4.,   8.,\n",
       "         2.,   3.,   3.,   4.,   8.,  32.,   0.,   0.,   2.,   2.,   0.,\n",
       "         0.,   3.,   3.,   0.,   1.,   3.,   4.,   3.,   3.,   0.,   1.,\n",
       "         3.,   3.,   3.,   2.,   2.,   5.,   8.,   3.,  16.,   8.,   2.,\n",
       "         8.,   1.,   3.,   1.,   1.,   8.,   8.,   5.,  32.,   8.,  40.,\n",
       "         1.,   8.,   3.,   8.,   3.,   4.,   1.,   3.,  24.,   3.,   1.,\n",
       "        64.,   2.,   8.,   2.,   8.,  56.,   8.,   3.,   3.,   2.,   8.,\n",
       "         2.,   8.,   2.,   1.,   1.,   1.,   8.,   2.,   2.,   2.,   1.,\n",
       "         2.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,   8.,   8.,   2.,\n",
       "         2.,   2.,   0.,   1.,   3.,   1.,   8.,   8.,   2.,   8.,   2.,\n",
       "         8.,   8.,   8.,   2.,   2.,   1.,   8.,   3.,   8.,   1.,   1.,\n",
       "         8.,   2.,   8.,   3.,   8.,   8.,   8.,   8.,   3.,  40.,  40.,\n",
       "        16.,  16.,   8.,   8.,   8.,   4.,   1.,   8.,  24.,   2.,   8.,\n",
       "         1.,   8.,  16.,   3.,  16.,   2.,   3.,   1.,   1.,   1.,   1.,\n",
       "        24.,   1.,   2.,   4.,  24.,   1.,   3.,   8.,   1.,   8.,  56.,\n",
       "         8.,  24.,   8.,  16.,   3.,   0.,   8.,   2.,   1.,   8.,   8.,\n",
       "         4.,   2.,   1.,  24.,   0.,   0.,   0.,   0.,   1.,  24.,   8.,\n",
       "         8.,   8.,  24.,   4.,   8.,   8.,   4.,   8.,   8.,  16.,   1.,\n",
       "        80.,   8.,   2.,   2.,   2.,  16.,   8.,   8.,   4.,   8.,   8.,\n",
       "         2.,   8.,   8.,   3.,   8.,   8.,   8.,  32.,   8.,   0.,   8.,\n",
       "         3.,   1.,   8.,   1.,   2.,   4.,   4.,   1.,   8.,   1.,   3.,\n",
       "         2.,   1.,   1.,   8.,   8.,   8.,   8.,   3.,  24.,   0.,  16.,\n",
       "         3.,   0.,   0.,   8.,  32.,   1.,   4.,   4.,   8.,   1.,   0.,\n",
       "         3.,  40.,   8.,   8.,   4.,   8.,   8.,   0.,   0.,   8.,   3.,\n",
       "         8.,   1.,  64.,   0.,  16.,   3.,   0.,   2.,   2.,   1.,   4.,\n",
       "        16.,   1.,   8.,   0.,   0.,   0.,   5.,   5.,   1.,   8.,   2.,\n",
       "         8.,   3.,   1.,   8., 120.,   8.,   0.,   1.,   3.,   2.,   3.,\n",
       "         8.,   4.,   8.,   1.,   8.,   8.,   0.,   0.,   1.,   3.,   2.,\n",
       "         1.,   3.,   1.,   4.,   8.,   1.,   1.,   1.,   8.,   2.,   1.,\n",
       "         8.,   4.,   8.,   2.,   3.,   8.,   5.,  32.,   2.,   1.,   4.,\n",
       "         8.,   8.,   8.,   4.,   1.,   1.,   2.,   3.,   1.,   3.,   3.,\n",
       "         3.,   2.,   3.,   8.,   8.,   3.,   8.,   3.,   2.,   2.,  16.,\n",
       "         3.,   3.,  24.,   3.,   3.,   8.,  16.,   2.,   4.,   2.,   8.,\n",
       "         8.,   8.,  16.,   8.,   0.,   8.,   2.,   3.,   8.,   0.,   0.,\n",
       "         0.,   8.,   8.,   8.,   2.,   4.,   3.,   4.,   4.,   4.,   8.,\n",
       "         8.,   1., 120.,   8.,   4.,   4.,   2.,  16.,   2.,   8.,   3.,\n",
       "         4.,   1.,   3.,   2.,   3.,   8.,   3.,   8.,   2.,   1.,   8.,\n",
       "         3.,   3.,   3.,   2.,   4.,   4.,   0.,  40.,  24.,   3.,   4.,\n",
       "         8.,   2.,   2.,   2.,   8.,   2.,   2.,   1.,   8.,   2.,   4.,\n",
       "         8.,   8.,   8.,   8.,   4.,   8.,   8.,   1.,   2., 112.,   1.,\n",
       "         1.,   8.,   8.,   8.,   2.,   1.,   2.,   4.,   1.,   4.,   4.,\n",
       "         8.,   8.,   4.,   4.,   8.,  16.,   4.,   1.,   5.,   2.,   3.,\n",
       "         1.,   1.,   3.,   2.,   2.,   8.,   1.,   4.,   1.,   2.,   8.,\n",
       "         8.,   1.,   3.,   8.,   3.,   2.,   2.,   2.,   1.,   2.,   8.,\n",
       "         3.,   4.,   8.,   3.,   1.,   1.,   8.,   1.,   8.,   3.,   8.,\n",
       "         8.,   8.,   0.,   3.,   1.,   3.,  24.,   1.,   8.,   8.,   8.,\n",
       "         4.,   8.,   2.,   2.,   3.,   1.,   8.,   8.,   2.,   0.,   0.,\n",
       "         4.,   0.,   2.,   8.,   2.,  32.,   1.,   3.,   1.,   3.,   3.,\n",
       "         4.,   2.,   8.,   8.,  16.,   2.,   3.,   2.,  80.,  24.,  16.,\n",
       "         2.,   2.,   3.,   2.,   8.,   3.,   2.,   8.,   2.,   3.,   8.,\n",
       "         3.,   2.,   8.,   3.,   8.,   2.,   3.,   2.,   2.,   2.,   2.,\n",
       "         2.,   2.,   8.,   3.,   3.,   3.,   2.,   2.,   3.,   3.,   2.,\n",
       "         2.,   8.,   2.,   5.,   3.,   2.,   2.,   2.,   2.,   2.,   2.,\n",
       "         2.,   2.,   2.,   2.,   3.,   3., 112.,   2.,   2.,   3.,   2.,\n",
       "         3.,   3.,   8.,   8.,   2.,   3.,   2.,   4.,   2.,   3.,   8.,\n",
       "         2.,   8.,   2.,   2.,   3.,   3.,   2.,   3.,   3.,   8.,  24.,\n",
       "         3.,   3.,   2., 104.,   8.,   8.,   8.,   8.,   8.,   8.,   2.,\n",
       "        24.,   2.,   3.,   2.,   2.,   8.,   2.,   8.,   3.,   2.,   4.,\n",
       "         8.,   2.,   2.,   8.,   3.,   2.,   3.,   8.,   1.,   2.,   8.,\n",
       "        64.,   8.,   2.,   2.,   3.,   1.,   0.,   2.,   0.,   1.,  48.,\n",
       "         8.,   8.,   8.,   3.,   8.,   2.,   2.,   2.,   8.,   2.,   8.,\n",
       "         8.,   1.,   8.,   3.,   8.,   8.,   8.,  24.,   8.,   2.,   0.,\n",
       "         0.,   3.,   2.,   2.,   3.,   3.,   8.,   2.,   3.,   3.,   4.,\n",
       "         2.,   8.,   4., 120.,  16.,   2.,   8.,   8.,  80.,   8.,   4.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_feature = array_feture_impor[:,14]\n",
    "Y_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740,)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature extraction\n",
    "model = ExtraTreesClassifier()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.035 0.105 0.059 0.061 0.037 0.035 0.022 0.021 0.025 0.064 0.052 0.053\n",
      " 0.01  0.025 0.397]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipemartinezs/.local/lib/python3.5/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_feature, Y_feature)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that we are given an importance score for each attribute where the larger the\n",
    "score, the more important the attribute. The scores highlight the importance of plas, age and\n",
    "mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
